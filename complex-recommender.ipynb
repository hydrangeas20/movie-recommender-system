{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Building A Complex Recommender System**\n",
    "\n",
    "We are building a sophisticated movie recommender system that utilizes a content-based approach to provide personalized suggestions. Our system will feature a robust recommender function and a well-structured pipeline created with Scikit-learn. By analyzing attributes such as genre, actors, directors, plot keywords, release year, language, and runtime, the system will identify and recommend movies with similar characteristics to enhance user experience and satisfaction. This approach ensures that recommendations are tailored to individual preferences based on detailed item comparisons.\n",
    "\n",
    "### Steps Needed for Coding the Recommender System:\n",
    "1.   Load and Merge Datasets\n",
    "2.   Data Cleaning \n",
    "3.   Feature Engineering \n",
    "4.   EDA \n",
    "5.   Build the Recommender System using KNN\n",
    "6.   Model Validation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & Merging Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets and merge them according to title\n",
    "\n",
    "movies = pd.read_csv(\"content/5000_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv(\"content/5000_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge them according to title\n",
    "movies_all = pd.merge(movies, credits, on='title')\n",
    "movies_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'release_date' is missing since it's crucial for feature engineering\n",
    "movies_all = movies_all.dropna(subset=['release_date'])\n",
    "\n",
    "# we can drop other rows with too many missing values or irrelevant columns\n",
    "# Drop rows where important categorical features are missing\n",
    "movies_all = movies_all.dropna(subset=['genres', 'cast', 'crew'])\n",
    "\n",
    "# Drop columns that are not useful for recommendation\n",
    "movies_all = movies_all.drop(columns=['homepage', 'status', 'tagline', 'overview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataframe\n",
    "movies_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Extracting year from release_date\n",
    "movies_all['release_year'] = pd.to_datetime(movies_all['release_date']).dt.year\n",
    "\n",
    "# Extracting the main genre from the genres column\n",
    "def get_main_genre(genres):\n",
    "    try:\n",
    "        genres_list = ast.literal_eval(genres)\n",
    "        if genres_list:\n",
    "            return genres_list[0]['name']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "movies_all['main_genre'] = movies_all['genres'].apply(get_main_genre)\n",
    "\n",
    "# Preprocess Cast and Crew\n",
    "def get_top_cast(cast, top_n=3):\n",
    "    try:\n",
    "        cast = ast.literal_eval(cast)\n",
    "        return [member['name'] for member in cast[:top_n]]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def get_director(crew):\n",
    "    try:\n",
    "        crew = ast.literal_eval(crew)\n",
    "        for member in crew:\n",
    "            if member['job'] == 'Director':\n",
    "                return member['name']\n",
    "        return ''\n",
    "    except:\n",
    "        return ''\n",
    "# Add new features (columns) to dataframe\n",
    "movies_all['top_cast'] = movies_all['cast'].apply(get_top_cast)\n",
    "movies_all['director'] = movies_all['crew'].apply(get_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flatten the 'top_cast' list for preprocessing\n",
    "movies_all['top_cast'] = movies_all['top_cast'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Update numerical and categorical columns\n",
    "numerical_cols = ['popularity', 'vote_average', 'vote_count', 'release_year']\n",
    "categorical_cols = ['main_genre', 'top_cast', 'director']\n",
    "\n",
    "# Ensure correct data types for numerical columns\n",
    "for col in numerical_cols:\n",
    "    movies_all[col] = pd.to_numeric(movies_all[col], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - Defining and Creating Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "movies_features = movies_all[numerical_cols + categorical_cols]\n",
    "\n",
    "# Define the pipeline with preprocessing and KNN\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', NearestNeighbors(n_neighbors=5, metric='cosine'))\n",
    "])\n",
    "\n",
    "# Fit the pipeline directly to the original features\n",
    "pipeline.fit(movies_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns distribution\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.histplot(movies_all[col].dropna(), kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the popularity vs vote average\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='popularity', y='vote_average', data=movies_all)\n",
    "plt.title('Popularity vs Vote Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get similar movies\n",
    "def recommend_movie(movie_title, n_neighbors=5):\n",
    "    # Handle case where movie is not found\n",
    "    if movie_title not in movies_all['title'].values:\n",
    "        return f\"Movie '{movie_title}' not found in the dataset.\"\n",
    "\n",
    "    # Get the index of the movie\n",
    "    movie_idx = movies_all[movies_all['title'] == movie_title].index[0]\n",
    "\n",
    "    # Extract the movie data as a DataFrame\n",
    "    movie_data = movies_features.iloc[movie_idx].to_frame().T\n",
    "\n",
    "    # Transform the input movie data\n",
    "    movie_data_transformed = pipeline.named_steps['preprocessor'].transform(movie_data)\n",
    "\n",
    "    # Find similar movies\n",
    "    distances, indices = pipeline.named_steps['knn'].kneighbors(movie_data_transformed)\n",
    "    similar_movie_indices = indices.flatten()\n",
    "\n",
    "    # Get titles of similar movies\n",
    "    similar_movies = movies_all.iloc[similar_movie_indices]['title']\n",
    "\n",
    "    # Filter out the input movie from its own recommendations\n",
    "    similar_movies = similar_movies[similar_movies != movie_title]\n",
    "\n",
    "    return similar_movies\n",
    "\n",
    "# Test the recommender system\n",
    "print(recommend_movie('The Matrix'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by manual inspection\n",
    "test_movies = ['The Matrix', 'Titanic', 'Avatar']\n",
    "for movie in test_movies:\n",
    "    print(f\"Recommendations for {movie}:\")\n",
    "    print(recommend_movie(movie))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Testing the recommender system with a movie name\n",
    "movie_name = 'Inception'\n",
    "print(f\"Recommendations for {movie_name}:\")\n",
    "print(recommend_movie(movie_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name = 'The Avengers'\n",
    "print(f\"Recommendations for {movie_name}:\")\n",
    "print(recommend_movie(movie_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name = 'Sherlock Holmes'\n",
    "print(f\"Recommendations for {movie_name}:\")\n",
    "print(recommend_movie(movie_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name = 'After'\n",
    "print(f\"Recommendations for {movie_name}:\")\n",
    "print(recommend_movie(movie_name))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
